<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Tutorial - Split Raster</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Tutorial";
        var mkdocs_page_input_path = "tutorial.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Split Raster
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Tutorial</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#create-image-sample-pairs">Create Image Sample Pairs</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#random-sampling-code">Random Sampling Code</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#use-the-output-of-the-split-raster-as-the-input-of-the-deep-learning-model">Use the output of the Split-Raster as the input of the Deep Learning Model</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#create-a-dataloader-for-the-split-raster-output">Create a DataLoader for the Split-Raster output</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#visualize-the-images-and-labels">Visualize the images and labels.</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#use-torchvision-to-visualize-the-images-and-labels">Use torchvision to visualize the images and labels</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#download-the-notebook">Download the Notebook</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../gis/">GIS-RS</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../about/">About</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Split Raster</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Tutorial</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="tutorial-for-using-split-raster-for-deep-learning">Tutorial for Using Split-Raster for Deep Learning</h1>
<p>This demo we will split a large image into small tiles. It is useful for deep learning and computer vision tasks. The package can also be used to split a large image into small tiles for other applications.</p>
<p>For example, we have a large image of size 1000-by-1000, and we want to split it into 256-by-256 tiles. The <code>SplitRaster</code> package successfully generate 16 256x256 images tiles with automatic padding on the edges. You can adjust the tile size and the overlap of the tiles for your own applications.</p>
<p>Setup your local or cloud environment for this demo.</p>
<p>This demo we use the python 3.10, but the package is compatible with python 3.7, 3.8, 3.9, 3.10, 3.11 and 3.12. </p>
<pre><code class="language-bash">&gt;pip install -q splitraster
</code></pre>
<h2 id="create-image-sample-pairs">Create Image Sample Pairs</h2>
<pre><code class="language-python">from splitraster import io

input_image_path = &quot;../data/raw/RGB.png&quot;
gt_image_path = &quot;../data/raw/GT.png&quot;

save_path = &quot;../data/processed/RGB&quot;
save_path_gt = &quot;../data/processed/GT&quot;

crop_size = 256
repetition_rate = 0 # &lt;----- change this value to 0.5 for 50% overlap
overwrite = True # &lt;----- change this value to False for no overwrite demo

n = io.split_image(input_image_path, save_path, crop_size,
                   repetition_rate=repetition_rate, overwrite=overwrite)
print(f&quot;{n} tiles sample of {input_image_path} are added at {save_path}&quot;)


n = io.split_image(gt_image_path, save_path_gt, crop_size,
                   repetition_rate=repetition_rate, overwrite=overwrite)
print(f&quot;{n} tiles sample of {gt_image_path} are added at {save_path_gt}&quot;)
</code></pre>
<p>Output:</p>
<pre><code class="language-bash">Input Image File Shape (H, W, D):(1000, 1000, 3)
crop_size = 256, stride = 256
Padding Image File Shape (H, W, D):(1024, 1024, 3)
... 

16 tiles sample of ../data/raw/GT.png are added at ../data/processed/GT
</code></pre>
<h2 id="random-sampling-code">Random Sampling Code</h2>
<p>If you want to create a small data set at the early stage for exploaration. Use the random sampling code, you can use the following code. The following code shows to geneate a 20 tiles (256x256) from the 1000x1000 image</p>
<pre><code class="language-python">from splitraster import io
input_image_path = &quot;../data/raw/RGB.png&quot;
gt_image_path = &quot;../data/raw/GT.png&quot;

input_save_path = &quot;../data/processed/Rand/RGB&quot;  
gt_save_path = &quot;../data/processed/Rand/GT&quot;

n = io.random_crop_image(input_image_path, input_save_path,  gt_image_path, gt_save_path, crop_size=256, crop_number=20, img_ext='.png', label_ext='.png', overwrite=True)

print(f&quot;{n} sample paris of {input_image_path, gt_image_path} are added at {input_save_path, gt_save_path}.&quot;)
</code></pre>
<p>Result:</p>
<pre><code class="language-bash">Generating: 100%|██████████| 20/20 [00:01&lt;00:00, 19.27img/s]20 sample paris of ('../data/raw/RGB.png', '../data/raw/GT.png') are added at ('../data/processed/Rand/RGB', '../data/processed/Rand/GT').
</code></pre>
<h2 id="use-the-output-of-the-split-raster-as-the-input-of-the-deep-learning-model">Use the output of the Split-Raster as the input of the Deep Learning Model</h2>
<p>We will use pytorch as the deep learning framework for this demo.</p>
<pre><code class="language-bash">pip install -q torch torchvision 
</code></pre>
<h2 id="create-a-dataloader-for-the-split-raster-output">Create a DataLoader for the Split-Raster output</h2>
<pre><code class="language-python">
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt

from skimage.io import imread, imsave
import os 
import numpy as np
</code></pre>
<p>create the <code>DatasetSegmentation</code> class to create a custom dataset class for the deep learning model.</p>
<pre><code class="language-python"># Create a custom dataset class
class DatasetSegmentation(torch.utils.data.Dataset):
    def __init__(self, image_path, label_path):
        self.imgfolder = image_path
        self.maskfolder = label_path
        self.imgs = list(sorted(os.listdir(image_path)))
        self.masks = list(sorted(os.listdir(label_path)))

    def __getitem__(self, idx):
        img_path = os.path.join(self.imgfolder, self.imgs[idx])
        mask_path = os.path.join(self.maskfolder, self.masks[idx])
        data = imread(img_path)
        data = np.moveaxis(data, -1, 0)
        label = imread(mask_path)
        label = label/255
        return torch.from_numpy(data).float(), torch.from_numpy(label).long()

    def __len__(self):
        return len(self.imgs)
AerialDataset = DatasetSegmentation(&quot;../data/processed/RGB&quot;, &quot;../data/processed/GT&quot;)
</code></pre>
<p>Create a DataLoader and read a batch of images from the Split-Raster output.</p>
<pre><code class="language-python">from torch.utils.data import DataLoader
train_dataloader = DataLoader(AerialDataset, batch_size=16, shuffle=False)
train_features, train_labels = next(iter(train_dataloader))
print(f&quot;Feature batch shape: {train_features.size()}&quot;)
print(f&quot;Labels batch shape: {train_labels.size()}&quot;)
</code></pre>
<p>Output:</p>
<pre><code class="language-bash">Feature batch shape: torch.Size([16, 3, 256, 256])
Labels batch shape: torch.Size([16, 256, 256])
</code></pre>
<h2 id="visualize-the-images-and-labels">Visualize the images and labels.</h2>
<pre><code class="language-python"># Select 16 random images from the training set
import random
idx = random.randint(0, 15)
img = train_features[idx].squeeze().numpy()
label = train_labels[idx].squeeze().numpy()

print(f&quot;Feature batch shape: {img.shape, img.max(), img.min()}&quot;)
print(f&quot;Labels batch shape: {label.shape, label.max(), label.min()}&quot;)



from matplotlib.pyplot import figure

figure(figsize=(12, 5), dpi=80)
plt.subplot(1,2,1)
img = np.moveaxis(img, 0, -1) # adjust the channel dimension
plt.imshow(img.astype(np.uint8) )
plt.subplot(1,2,2)

plt.imshow(label.astype(np.uint8), cmap=&quot;gray&quot;)
plt.show()

</code></pre>
<p>Feature batch shape: ((3, 256, 256), 221.0, 1.0)
Labels batch shape: ((256, 256), 1, 0)</p>
<p><img alt="output_img_gt.png" src="../img/output_img_gt.png" /></p>
<h2 id="use-torchvision-to-visualize-the-images-and-labels">Use torchvision to visualize the images and labels</h2>
<pre><code class="language-python">import torchvision
grid_img = torchvision.utils.make_grid(train_features/255, nrow=4)
grid_label = torchvision.utils.make_grid(train_labels.unsqueeze_(1), nrow=4)
print(grid_img.shape)
print(grid_label.shape)
figure(figsize=(12, 18), dpi=80)
plt.subplot(1,2,1)
plt.imshow(grid_img.permute(1, 2, 0))
plt.subplot(1,2,2)
plt.imshow(grid_label[0,:,:], cmap='gray')
plt.show()
</code></pre>
<p>Output:</p>
<pre><code>(torch.Size([3, 1034, 1034]), torch.Size([3, 1034, 1034]))
</code></pre>
<p><img alt="output-grid.png" src="../img/output-grid.png" /></p>
<h2 id="download-the-notebook">Download the Notebook</h2>
<p>Find the full code in this  Notebook Tutorial: <a href="https://github.com/cuicaihao/split_raster/blob/master/notebooks/Tutorial.ipynb">SplitRaster Tutorial</a>.</p>
<hr />
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href=".." class="btn btn-neutral float-left" title="Home"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../gis/" class="btn btn-neutral float-right" title="GIS-RS">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href=".." style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../gis/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
